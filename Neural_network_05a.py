# -*- coding: utf-8 -*-
"""
Created on Tue Aug 27 19:05:57 2019

@author: fespinosa
"""

# first neural network with keras tutorial
import numpy as np
from keras.models import Sequential
from keras.layers import Dense

# load the dataset
#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')
# split into input (X) and output (y) variables
X = np.array(
        [
        [703,849,8.3158,0.0088,7.5048,11,1,28,1.3228,0.3929,0.5197,2,5],
        [712,860,8.2632,0.0088,7.4822,1,1,28,0.1210,0.0357,0.0043,1,13],
        [712,860,8.2632,0.0088,7.4822,2,1,28,0.2420,0.0714,0.0173,1,10],
        [712,860,8.2632,0.0088,7.4822,3,1,28,0.3631,0.1071,0.0389,1,6],
        [712,860,8.2632,0.0088,7.4822,4,1,28,0.4841,0.1429,0.0692,1,1],
        [712,860,8.2632,0.0088,7.4822,5,1,28,0.6051,0.1786,0.1081,2,16],
        [712,860,8.2632,0.0088,7.4822,6,1,28,0.7261,0.2143,0.1556,2,12],
        [712,860,8.2632,0.0088,7.4822,7,1,28,0.8471,0.2500,0.2118,2,9],
        [712,867,8.2000,0.0087,7.2979,1,1,28,0.1220,0.0357,0.0044,1,14],
        [712,867,8.2000,0.0087,7.2979,2,1,28,0.2439,0.0714,0.0174,1,10],
        [716,867,8.1579,0.0087,7.4852,3,1,28,0.3677,0.1071,0.0394,1,7],
        [716,867,8.1579,0.0087,7.4852,4,1,28,0.4903,0.1429,0.0701,1,5],
        [716,867,8.1579,0.0087,7.4852,5,1,28,0.6129,0.1786,0.1095,2,14],
        [716,872,8.0000,0.0085,7.3280,1,1,28,0.1250,0.0357,0.0045,1,14],
        [727,872,8.2105,0.0087,7.4592,2,1,28,0.2436,0.0714,0.0174,1,11],
        [727,872,8.2105,0.0087,7.4592,3,1,28,0.3654,0.1071,0.0391,1,9],
        [727,872,8.2105,0.0087,7.4592,4,1,28,0.4872,0.1429,0.0696,1,3],
        [727,872,8.2105,0.0087,7.4592,5,1,28,0.6090,0.1786,0.1088,2,8],
        [727,872,8.2105,0.0087,7.4592,6,1,28,0.7308,0.2143,0.1566,2,7],
        [727,872,8.2105,0.0087,7.4592,7,1,28,0.8526,0.2500,0.2132,2,7],
        [727,872,8.2105,0.0087,7.4592,8,1,28,0.9744,0.2857,0.2784,2,8],
        [727,872,8.2105,0.0087,7.4592,9,1,28,1.0962,0.3214,0.3523,2,6],
        [727,872,8.2105,0.0087,7.4592,10,1,28,1.2180,0.3571,0.4349,2,5],
        [727,882,8.3000,0.0088,7.2808,1,1,28,0.1205,0.0357,0.0043,1,17],
        [727,882,8.3000,0.0088,7.2808,2,1,28,0.2410,0.0714,0.0172,1,11],
        [730,884,7.8500,0.0083,7.3775,1,1,28,0.1274,0.0357,0.0045,1,11],
        [730,885,7.5238,0.0080,7.3460,1,1,28,0.1329,0.0357,0.0047,1,13],
        [730,885,7.5238,0.0080,7.3460,2,1,28,0.2658,0.0714,0.0190,1,9],
        [731,885,7.7500,0.0082,7.4557,3,1,28,0.3871,0.1071,0.0415,1,8],
        [756,885,8.1053,0.0086,7.4826,4,1,28,0.4935,0.1429,0.0705,1,2],
        [756,885,8.1053,0.0086,7.4826,5,1,28,0.6169,0.1786,0.1102,2,18],
        [756,885,8.1053,0.0086,7.4826,6,1,28,0.7403,0.2143,0.1586,2,15],
        [756,885,8.1053,0.0086,7.4826,7,1,28,0.8636,0.2500,0.2159,2,11],
        [756,885,8.1053,0.0086,7.4826,8,1,28,0.9870,0.2857,0.2820,2,9],
        [756,893,8.1000,0.0086,7.2931,1,1,28,0.1235,0.0357,0.0044,1,17],
        [756,893,8.1000,0.0086,7.2931,2,1,28,0.2469,0.0714,0.0176,1,9],
        [756,893,8.1000,0.0086,7.2931,3,1,28,0.3704,0.1071,0.0397,1,4],
        [756,893,8.1000,0.0086,7.2931,4,1,28,0.4938,0.1429,0.0706,1,3],
        [756,893,8.1000,0.0086,7.2931,5,1,28,0.6173,0.1786,0.1102,2,15],
        [756,893,8.1000,0.0086,7.2931,6,1,28,0.7407,0.2143,0.1587,2,12],
        [756,893,8.1000,0.0086,7.2931,7,1,28,0.8642,0.2500,0.2161,2,12],
        [756,893,8.1000,0.0086,7.2931,8,1,28,0.9877,0.2857,0.2822,2,10],
        [756,893,8.1000,0.0086,7.2931,9,1,28,1.1111,0.3214,0.3571,2,6],
        [756,893,8.1000,0.0086,7.2931,10,1,28,1.2346,0.3571,0.4409,2,4],
        [756,893,8.1000,0.0086,7.2931,11,1,28,1.3580,0.3929,0.5336,2,2],
        [756,893,8.1000,0.0086,7.2931,12,1,28,1.4815,0.4286,0.6350,2,1],
        [756,893,8.1000,0.0086,7.2931,13,1,28,1.6049,0.4643,0.7452,2,1],
        [756,893,8.1000,0.0086,7.2931,14,1,28,1.7284,0.5000,0.8642,2,1],
        [756,893,8.1000,0.0086,7.2931,15,1,28,1.8519,0.5357,0.9921,2,1],
        [756,893,8.1000,0.0086,7.2931,16,1,28,1.9753,0.5714,1.1287,3,7],
        [756,893,8.1000,0.0086,7.2931,17,1,28,2.0988,0.6071,1.2742,3,8],
        [756,893,8.1000,0.0086,7.2931,18,1,28,2.2222,0.6429,1.4287,3,8],
        [756,893,8.1000,0.0086,7.2931,19,1,28,2.3457,0.6786,1.5918,3,8],
        [756,893,8.1000,0.0086,7.2931,20,1,28,2.4691,0.7143,1.7637,3,6],
        [759,893,7.2105,0.0077,6.3377,21,1,28,2.9124,0.7500,2.1843,3,5],
        [759,893,7.2105,0.0077,6.3377,22,1,28,3.0511,0.7857,2.3972,3,3],
        [759,893,7.2105,0.0077,6.3377,23,1,28,3.1898,0.8214,2.6201,3,3],
        [760,916,8.2632,0.0088,7.1587,1,1,28,0.1210,0.0357,0.0043,1,17],
        [769,916,8.6667,0.0092,7.1414,2,1,28,0.2308,0.0714,0.0165,1,9],
        [769,916,8.6667,0.0092,7.1414,3,1,28,0.3462,0.1071,0.0371,1,5],
        [769,916,8.6667,0.0092,7.1414,4,1,28,0.4615,0.1429,0.0659,1,5],
        [769,916,8.6667,0.0092,7.1414,5,1,28,0.5769,0.1786,0.1030,2,14],
        [769,921,8.4737,0.0090,6.9990,1,1,28,0.1180,0.0357,0.0042,1,18],
        [769,921,8.4737,0.0090,6.9990,2,1,28,0.2360,0.0714,0.0169,1,11],
        [769,923,8.1500,0.0087,6.9662,1,1,28,0.1227,0.0357,0.0044,1,17],
        [769,923,8.1500,0.0087,6.9662,2,1,28,0.2454,0.0714,0.0175,1,12],
        [769,923,8.1500,0.0087,6.9662,3,1,28,0.3681,0.1071,0.0394,1,5],
        [781,923,8.1053,0.0086,7.1443,4,1,28,0.4935,0.1429,0.0705,1,3],
        [781,923,8.1053,0.0086,7.1443,5,1,28,0.6169,0.1786,0.1102,2,16],
        [781,923,8.1053,0.0086,7.1443,6,1,28,0.7403,0.2143,0.1586,2,13],
        [781,923,8.1053,0.0086,7.1443,7,1,28,0.8636,0.2500,0.2159,2,13],
        [781,923,8.1053,0.0086,7.1443,8,1,28,0.9870,0.2857,0.2820,2,11],
        [781,923,8.1053,0.0086,7.1443,9,1,28,1.1104,0.3214,0.3569,2,8],
        [781,923,8.1053,0.0086,7.1443,10,1,28,1.2338,0.3571,0.4406,2,7],
        [781,923,8.1053,0.0086,7.1443,11,1,28,1.3571,0.3929,0.5332,2,6],
        [781,923,8.1053,0.0086,7.1443,12,1,28,1.4805,0.4286,0.6345,2,5],
        [781,923,8.1053,0.0086,7.1443,13,1,28,1.6039,0.4643,0.7447,2,4],
        [781,923,8.1053,0.0086,7.1443,14,1,28,1.7273,0.5000,0.8637,2,2],
        [781,923,8.1053,0.0086,7.1443,15,1,28,1.8506,0.5357,0.9914,2,1],
        [785,923,7.8889,0.0084,7.2793,16,1,28,2.0282,0.5714,1.1589,3,5],
        [785,923,7.8889,0.0084,7.2793,17,1,28,2.1549,0.6071,1.3082,3,5],
        [785,923,7.8889,0.0084,7.2793,18,1,28,2.2817,0.6429,1.4669,3,5],
        [785,941,8.4211,0.0089,7.4362,1,1,28,0.1187,0.0357,0.0042,1,20],
        [813,941,8.6667,0.0092,7.5645,2,1,28,0.2308,0.0714,0.0165,1,13],
        [813,941,8.6667,0.0092,7.5645,3,1,28,0.3462,0.1071,0.0371,1,7],
        [813,941,8.6667,0.0092,7.5645,4,1,28,0.4615,0.1429,0.0659,1,1],
        [813,945,8.4211,0.0089,7.4362,1,1,28,0.1187,0.0357,0.0042,1,19],
        [813,945,8.4211,0.0089,7.4362,2,1,28,0.2375,0.0714,0.0170,1,14],
        [813,945,8.4211,0.0089,7.4362,3,1,28,0.3562,0.1071,0.0381,1,5],
        [813,948,8.1500,0.0087,7.3435,1,1,28,0.1227,0.0357,0.0044,1,14],
        [813,948,8.1500,0.0087,7.3435,2,1,28,0.2454,0.0714,0.0175,1,10],
        [813,948,8.1500,0.0087,7.3435,3,1,28,0.3681,0.1071,0.0394,1,7],
        [813,951,7.9048,0.0084,7.2500,1,1,28,0.1265,0.0357,0.0045,1,13],
        [813,952,7.5909,0.0081,7.2278,1,1,28,0.1317,0.0357,0.0047,1,15],
        [813,952,7.5909,0.0081,7.2278,2,1,28,0.2635,0.0714,0.0188,1,8],
        [813,952,7.5909,0.0081,7.2278,3,1,28,0.3952,0.1071,0.0423,1,6],
        [813,952,7.5909,0.0081,7.2278,4,1,28,0.5269,0.1429,0.0753,1,4],
        [813,952,7.5909,0.0081,7.2278,5,1,28,0.6587,0.1786,0.1176,2,11],
        [813,952,7.5909,0.0081,7.2278,6,1,28,0.7904,0.2143,0.1694,2,9],
        [813,952,7.5909,0.0081,7.2278,7,1,28,0.9222,0.2500,0.2306,2,7],
        [813,952,7.5909,0.0081,7.2278,8,1,28,1.0539,0.2857,0.3011,2,7],
        [813,952,7.5909,0.0081,7.2278,9,1,28,1.1856,0.3214,0.3811,2,6],
        [813,952,7.5909,0.0081,7.2278,10,1,28,1.3174,0.3571,0.4704,2,5],
        [813,952,7.5909,0.0081,7.2278,11,1,28,1.4491,0.3929,0.5694,2,5],
        [813,952,7.5909,0.0081,7.2278,12,1,28,1.5808,0.4286,0.6775,2,4]
        ]
        )
y = np.array([
	[1,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0,0,1,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]
            ]).T

# define the keras model
model = Sequential()
model.add(Dense(12, input_dim=13, activation='relu'))
model.add(Dense(13, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# fit the keras model on the dataset
model.fit(X, y, epochs=1500, batch_size=10)

# evaluate the keras model
_, accuracy = model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))

Xp = np.array([
	[813,952,7.5909,0.0081,7.2278,13,1,28,1.7126,0.4643,0.7952,2,3]
    ])
# make class predictions with the model
predictions = model.predict_classes(Xp)
# summarize the first 5 cases
for i in range(5):
    print('%s => %d (expected %d)' % (Xp[i].tolist(), predictions[i], y[i]))