# -*- coding: utf-8 -*-
"""
Created on Tue Aug 27 19:05:57 2019

@author: fespinosa
"""

# first neural network with keras tutorial
import numpy as np
from keras.models import Sequential
from keras.layers import Dense

# load the dataset
#dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')
# split into input (X) and output (y) variables
X = np.array(
        [
        [8.8889,0.0094,6.6407,4,1,22,0.4500,0.1818,0.0818,1,1],
        [9.0000,0.0096,6.8169,5,1,22,0.5556,0.2273,0.1263,2,26],
        [9.5000,0.0101,6.7175,6,1,22,0.6316,0.2727,0.1722,2,24],
        [10.0667,0.0107,6.5571,7,1,22,0.6954,0.3182,0.2213,2,20],
        [10.0667,0.0107,6.5571,8,1,22,0.7947,0.3636,0.2890,2,15],
        [10.0667,0.0107,6.5571,9,1,22,0.8940,0.4091,0.3657,2,12],
        [10.0667,0.0107,6.5571,10,1,22,0.9934,0.4545,0.4515,2,9],
        [10.0667,0.0107,6.5571,11,1,22,1.0927,0.5000,0.5464,2,8],
        [10.0667,0.0107,6.5571,12,1,22,1.1920,0.5455,0.6502,2,8],
        [10.0667,0.0107,6.5571,13,1,22,1.2914,0.5909,0.7631,2,7],
        [10.0667,0.0107,6.5571,14,1,22,1.3907,0.6364,0.8850,2,3],
        [10.0667,0.0107,6.5571,15,1,22,1.4901,0.6818,1.0160,3,10],
        [10.0667,0.0107,6.5571,16,1,22,1.5894,0.7273,1.1560,3,9],
        [10.0667,0.0107,6.5571,17,1,22,1.6887,0.7727,1.3049,3,9],
        [10.5000,0.0111,6.5670,1,1,22,0.0952,0.0455,0.0043,1,20],
        [10.5000,0.0111,6.5670,2,1,22,0.1905,0.0909,0.0173,1,13],
        [10.5000,0.0111,6.5670,3,1,22,0.2857,0.1364,0.0390,1,10],
        [10.0588,0.0107,6.6108,1,1,22,0.0994,0.0455,0.0045,1,20],
        [9.5556,0.0101,6.7513,1,1,22,0.1047,0.0455,0.0048,1,17],
        [9.5556,0.0101,6.7513,2,1,22,0.2093,0.0909,0.0190,1,10],
        [9.1579,0.0097,6.7844,1,1,22,0.1092,0.0455,0.0050,1,17],
        [9.1579,0.0097,6.7844,2,1,22,0.2184,0.0909,0.0199,1,12],
        [9.1579,0.0097,6.7844,3,1,22,0.3276,0.1364,0.0447,1,8],
        [9.1579,0.0097,6.7844,4,1,22,0.4368,0.1818,0.0794,1,3],
        [8.5000,0.0090,6.3530,5,1,22,0.5882,0.2273,0.1337,2,19],
        [8.5000,0.0090,6.3530,6,1,22,0.7059,0.2727,0.1925,2,14],
        [8.5000,0.0090,6.3530,7,1,22,0.8235,0.3182,0.2620,2,10],
        [8.8235,0.0094,6.3915,8,1,22,0.9067,0.3636,0.3297,2,11],
        [8.8235,0.0094,6.3915,9,1,22,1.0200,0.4091,0.4173,2,7],
        [8.8235,0.0094,6.3915,10,1,22,1.1333,0.4545,0.5151,2,5],
        [8.8235,0.0094,6.3915,11,1,22,1.2467,0.5000,0.6234,2,4],
        [8.8235,0.0094,6.3915,12,1,22,1.3600,0.5455,0.7419,2,3],
        [8.8235,0.0094,6.3915,13,1,22,1.4733,0.5909,0.8706,2,1],
        [8.8235,0.0094,6.3915,14,1,22,1.5867,0.6364,1.0098,3,10],
        [8.8235,0.0094,6.3915,15,1,22,1.7000,0.6818,1.1591,3,10],
        [9.1667,0.0097,6.3705,1,1,22,0.1091,0.0455,0.0050,1,17],
        [9.1667,0.0097,6.3705,2,1,22,0.2182,0.0909,0.0198,1,11],
        [9.1667,0.0097,6.3705,3,1,22,0.3273,0.1364,0.0446,1,9],
        [9.1667,0.0097,6.3705,4,1,22,0.4364,0.1818,0.0793,1,3],
        [9.1667,0.0097,6.3705,5,1,22,0.5455,0.2273,0.1240,2,19],
        [8.9474,0.0095,6.2700,1,1,22,0.1118,0.0455,0.0051,1,19],
        [8.6667,0.0092,6.3246,2,1,22,0.2308,0.0909,0.0210,1,10],
        [9.1176,0.0097,6.2203,3,1,22,0.3290,0.1364,0.0449,1,5],
        [9.1176,0.0097,6.2203,4,1,22,0.4387,0.1818,0.0798,1,2],
        [9.1176,0.0097,6.2203,5,1,22,0.5484,0.2273,0.1247,2,23],
        [9.1176,0.0097,6.2203,6,1,22,0.6581,0.2727,0.1795,2,20],
        [9.1176,0.0097,6.2203,7,1,22,0.7677,0.3182,0.2443,2,15],
        [9.1176,0.0097,6.2203,8,1,22,0.8774,0.3636,0.3190,2,12],
        [9.1176,0.0097,6.2203,9,1,22,0.9871,0.4091,0.4038,2,10],
        [9.1176,0.0097,6.2203,10,1,22,1.0968,0.4545,0.4985,2,7],
        [9.1176,0.0097,6.2203,11,1,22,1.2065,0.5000,0.6033,2,6],
        [9.1176,0.0097,6.2203,12,1,22,1.3161,0.5455,0.7179,2,6],
        [9.1176,0.0097,6.2203,13,1,22,1.4258,0.5909,0.8425,2,5],
        [9.0000,0.0096,6.3934,14,1,22,1.5556,0.6364,0.9900,2,1],
        [9.0000,0.0096,6.3934,15,1,22,1.6667,0.6818,1.1364,3,8],
        [9.3529,0.0099,6.3611,1,1,22,0.1069,0.0455,0.0049,1,18],
        [9.3529,0.0099,6.3611,2,1,22,0.2138,0.0909,0.0194,1,14],
        [9.3529,0.0099,6.3611,3,1,22,0.3208,0.1364,0.0438,1,11],
        [9.3529,0.0099,6.3611,4,1,22,0.4277,0.1818,0.0778,1,6],
        [9.3529,0.0099,6.3611,5,1,22,0.5346,0.2273,0.1215,2,20],
        [9.3529,0.0099,6.3611,6,1,22,0.6415,0.2727,0.1749,2,17],
        [9.3529,0.0099,6.3611,7,1,22,0.7484,0.3182,0.2381,2,11],
        [9.3529,0.0099,6.3611,8,1,22,0.8553,0.3636,0.3110,2,10],
        [9.3529,0.0099,6.3611,9,1,22,0.9623,0.4091,0.3937,2,9],
        [9.3529,0.0099,6.3611,10,1,22,1.0692,0.4545,0.4860,2,6],
        [9.3529,0.0099,6.3611,11,1,22,1.1761,0.5000,0.5881,2,4],
        [9.1250,0.0097,6.4892,12,1,22,1.3151,0.5455,0.7174,2,3],
        [9.1250,0.0097,6.4892,13,1,22,1.4247,0.5909,0.8419,2,2],
        [9.1250,0.0097,6.4892,14,1,22,1.5342,0.6364,0.9764,2,1],
        [9.4118,0.0100,6.3991,1,1,22,0.1062,0.0455,0.0048,1,21],
        [9.4118,0.0100,6.3991,2,1,22,0.2125,0.0909,0.0193,1,14],
        [9.4118,0.0100,6.3991,3,1,22,0.3187,0.1364,0.0435,1,10],
        [9.4118,0.0100,6.3991,4,1,22,0.4250,0.1818,0.0773,1,2],
        [9.2353,0.0098,6.5037,1,1,22,0.1083,0.0455,0.0049,1,19],
        [9.2353,0.0098,6.5037,2,1,22,0.2166,0.0909,0.0197,1,15],
        [8.8333,0.0094,6.5341,1,1,22,0.1132,0.0455,0.0052,1,21],
        [8.8333,0.0094,6.5341,2,1,22,0.2264,0.0909,0.0206,1,15],
        [8.8333,0.0094,6.5341,3,1,22,0.3396,0.1364,0.0463,1,9],
        [8.8333,0.0094,6.5341,4,1,22,0.4528,0.1818,0.0823,1,2],
        [8.8333,0.0094,6.5341,5,1,22,0.5660,0.2273,0.1287,2,23],
        [8.8333,0.0094,6.5341,6,1,22,0.6792,0.2727,0.1852,2,17],
        [8.8333,0.0094,6.5341,7,1,22,0.7925,0.3182,0.2522,2,14],
        [8.8333,0.0094,6.5341,8,1,22,0.9057,0.3636,0.3293,2,10],
        [8.8333,0.0094,6.5341,9,1,22,1.0189,0.4091,0.4168,2,6],
        [8.8333,0.0094,6.5341,10,1,22,1.1321,0.4545,0.5145,2,6],
        [8.8333,0.0094,6.5341,11,1,22,1.2453,0.5000,0.6227,2,5],
        [8.8333,0.0094,6.5341,12,1,22,1.3585,0.5455,0.7411,2,4],
        [8.8333,0.0094,6.5341,13,1,22,1.4717,0.5909,0.8696,2,1],
        [8.8333,0.0094,6.5341,14,1,22,1.5849,0.6364,1.0086,3,8],
        [8.8333,0.0094,6.5341,15,1,22,1.6981,0.6818,1.1578,3,7],
        [8.8333,0.0094,6.5341,16,1,22,1.8113,0.7273,1.3174,3,6],
        [8.2941,0.0088,6.3224,17,1,22,2.0496,0.7727,1.5837,3,5],
        [8.2941,0.0088,6.3224,18,1,22,2.1702,0.8182,1.7757,3,4],
        [8.2941,0.0088,6.3224,19,1,22,2.2908,0.8636,1.9783,3,4],
        [8.8889,0.0094,6.6155,1,1,22,0.1125,0.0455,0.0051,1,16],
        [8.8889,0.0094,6.6155,2,1,22,0.2250,0.0909,0.0205,1,10],
        [8.5263,0.0091,6.6203,1,1,22,0.1173,0.0455,0.0053,1,19],
        [8.5263,0.0091,6.6203,2,1,22,0.2346,0.0909,0.0213,1,12],
        [8.6111,0.0091,6.7917,3,1,22,0.3484,0.1364,0.0475,1,7],
        [8.6111,0.0091,6.7917,4,1,22,0.4645,0.1818,0.0844,1,1],
        [8.6111,0.0091,6.7917,5,1,22,0.5806,0.2273,0.1320,2,22],
        [8.6111,0.0091,6.7917,6,1,22,0.6968,0.2727,0.1900,2,22],
        [8.6111,0.0091,6.7917,7,1,22,0.8129,0.3182,0.2587,2,19],
        [8.6111,0.0091,6.7917,8,1,22,0.9290,0.3636,0.3378,2,16],
        [8.6111,0.0091,6.7917,9,1,22,1.0452,0.4091,0.4276,2,12]
    ]
        )
y = np.array([
        [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]
            ]).T

# define the keras model
model = Sequential()
model.add(Dense(12, input_dim=11, activation='relu'))
model.add(Dense(11, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# fit the keras model on the dataset
model.fit(X, y, epochs=1500, batch_size=10)

# evaluate the keras model
_, accuracy = model.evaluate(X, y)
print('Accuracy: %.2f' % (accuracy*100))

Xp = np.array(
    [
        [8.6111,0.0091,6.7917,10,1,22,1.1613,0.4545,0.5278,2,9],
        [10.4000,0.0110,6.6713,6,1,23,0.5769,0.2609,0.1505,2,16],
        [7.6667,0.0081,7.0159,20,1,25,2.6087,0.8000,2.0870,3,4],
        [14.1818,0.0151,13.9403,2,1,47,0.1410,0.0426,0.0060,1,16],
        [10.5625,0.0112,10.8222,9,1,43,0.8521,0.2093,0.1783,2,15],
        [9.6250,0.0102,6.9810,5,3,32,0.5195,0.1563,0.0812,1,2],
        [6.1304,0.0065,5.6361,25,1,20,4.0780,1.2500,5.0975,3,3],
        [10.8571,0.0115,9.7090,7,1,33,0.6447,0.2121,0.1367,2,20],
        [7.0000,0.0074,5.2554,13,1,19,1.8571,0.6842,1.2706,3,7],
        [8.5263,0.0091,6.7774,5,2,25,0.5864,0.2000,0.1173,2,24],
        [7.9000,0.0084,7.2381,12,1,32,1.5190,0.3750,0.5696,2,8],
        [11.7500,0.0125,12.0078,19,2,41,1.6170,0.4634,0.7493,2,5],
        [8.3125,0.0088,6.2020,35,2,24,4.2105,1.4583,6.1402,3,1],
        [10.2500,0.0109,7.2758,9,1,26,0.8780,0.3462,0.3040,2,12],
        [12.6154,0.0134,11.9778,2,2,37,0.1585,0.0541,0.0086,1,14],
        [8.2500,0.0088,5.2903,10,1,19,1.2121,0.5263,0.6379,2,7],
        [10.2500,0.0109,9.9027,5,1,35,0.4878,0.1429,0.0697,1,3],
        [9.5882,0.0102,8.2324,6,1,28,0.6258,0.2143,0.1341,2,22],
        [7.7368,0.0082,6.6637,13,1,24,1.6803,0.5417,0.9102,2,1],
        [10.4118,0.0111,9.3624,4,1,39,0.3842,0.1026,0.0394,1,4],
        [7.9000,0.0084,6.5719,5,1,22,0.6329,0.2273,0.1439,2,18],
        [8.4500,0.0090,4.2834,2,2,18,0.2367,0.1111,0.0263,1,8],
        [8.5000,0.0090,7.6540,6,2,31,0.7059,0.1935,0.1366,2,21],
        [10.9286,0.0116,8.2848,6,1,24,0.5490,0.2500,0.1373,2,19],
        [8.2500,0.0088,7.8605,3,1,31,0.3636,0.0968,0.0352,1,5],
        [11.4615,0.0122,12.4630,9,1,47,0.7852,0.1915,0.1504,2,17],
        [12.0000,0.0127,7.9267,14,3,31,1.1667,0.4516,0.5269,2,10],
        [9.2353,0.0098,6.9750,2,1,23,0.2166,0.0870,0.0188,1,11],
        [9.7059,0.0103,10.7253,3,1,38,0.3091,0.0789,0.0244,1,9],
        [10.1176,0.0107,8.4567,5,1,28,0.4942,0.1786,0.0883,1,1],
        [9.2941,0.0099,7.8198,1,1,27,0.1076,0.0370,0.0040,1,17],
        [8.4444,0.0090,9.6966,6,1,37,0.7105,0.1622,0.1152,2,25],
        [8.5789,0.0091,7.8426,17,1,27,1.9816,0.6296,1.2476,3,8],
        [6.1154,0.0065,4.6931,4,1,20,0.6541,0.2000,0.1308,2,23],
        [10.6250,0.0113,8.5577,1,1,26,0.0941,0.0385,0.0036,1,19],
        [7.3000,0.0077,4.7864,15,1,18,2.0548,0.8333,1.7123,3,5],
        [10.8571,0.0115,4.5959,14,2,20,1.2895,0.7000,0.9027,2,2],
        [9.5833,0.0102,9.4115,43,1,35,4.4870,1.2286,5.5127,3,2],
        [10.9333,0.0116,9.8486,1,2,42,0.0915,0.0238,0.0022,1,22],
        [8.4737,0.0090,11.0424,2,1,44,0.2360,0.0455,0.0107,1,13],
        [10.0000,0.0106,9.0692,1,1,36,0.1000,0.0278,0.0028,1,20],
        [14.9091,0.0158,11.9883,20,4,35,1.3415,0.5714,0.7665,2,4],
        [8.6190,0.0091,9.3324,3,1,45,0.3481,0.0667,0.0232,1,10],
        [11.3571,0.0121,13.8337,4,1,51,0.3522,0.0784,0.0276,1,7],
        [6.6087,0.0070,5.7766,14,1,23,2.1184,0.6087,1.2895,3,6],
        [10.5625,0.0112,6.0412,7,2,25,0.6627,0.2800,0.1856,2,14],
        [8.7368,0.0093,7.8260,3,1,34,0.3434,0.0882,0.0303,1,6],
        [13.1667,0.0140,12.7399,2,1,50,0.1519,0.0400,0.0061,1,15],
        [16.1000,0.0171,10.8023,3,5,38,0.1863,0.0789,0.0147,1,12],
        [10.1111,0.0107,9.8426,1,1,37,0.0989,0.0270,0.0027,1,21],
        [10.0625,0.0107,7.3269,1,1,27,0.0994,0.0370,0.0037,1,18],
        [7.5000,0.0080,6.2650,12,1,27,1.6000,0.4444,0.7110,2,6],
        [9.3125,0.0099,7.7839,11,1,27,1.1812,0.4074,0.4812,2,11],
        [7.2727,0.0077,6.0089,4,1,22,0.5500,0.1818,0.1000,2,26],
        [14.4545,0.0153,13.8391,12,1,48,0.8302,0.2500,0.2076,2,13],
        [9.1875,0.0098,9.0913,15,1,29,1.6327,0.5172,0.8444,2,3]
    ])
# make class predictions with the model
predictions = model.predict_classes(Xp)
# summarize the first 5 cases
for i in range(5):
    print('%s => %d (expected %d)' % (Xp[i].tolist(), predictions[i], y[i]))